{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fce00f",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "### Monte Carlo and expectation\n",
    "The problem is to estimate $E[g(X)]=\\int g(x) p(x) dx$, where $X \\sim p(x)$. Depending on whether we can sample from **p(x)** or not, we get two versions of Monte Carlo for expectation:\n",
    "<br>a. **Direct Sampling** (if you can sample from $p(x)$):\n",
    "1. Generate $n$ samples from $p(x)$: $x_i\\sim p(x)$\n",
    "2. Compute $g(x_i)$ for each sample.\n",
    "3. Average:\n",
    "$E[g(X)]\\approx\\frac{1}{n}\\sum_{i=1}^n g(x_i)$\n",
    "\n",
    "**Reminder:** Standard Error is:\n",
    "- $SE=\\frac{\\sigma}{\\sqrt{n}}$, where $\\sigma^2=Var(g(X))$\n",
    "\n",
    "b.1. **Importance Sampling** (if you can't sample from $p(x)$ directly):\n",
    "1. Choose a proposal distribution $q(x)$ that is easy to sample from\n",
    "2. Generate $n$ samples from $q(x)$: $x_i\\sim q(x)$\n",
    "3. Weight each sample by $w_i=p(x_i)/q(x_i)$\n",
    "4. Compute weighted average: $E[g(X)]≈\\frac{1}{n}\\sum_{i=1}^n g(x_i)⋅\\frac{p(x_i)}{q(x_i)}$\n",
    "\n",
    "b.2. **Self-Normalized Importance Sampling** (when p is unnormalized): Assumption is that we only know $\\tilde{p}(x)$ where $p(x)=\\frac{\\tilde{p}(x)}{Z}$, and $Z=\\int \\tilde{p}(x) dx$ is unknown.\n",
    "<br>$E_p[g(X)]≈\\frac{\\sum_{i=1}^n w_i\\cdot g(x_i)}{\\sum_{i=1}^n w_i}$, $w_i=\\frac{\\tilde{p}(x_i)}{q(x_i)}$, $x_i \\sim q$\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "In the following:\n",
    "- We first give the Python code for **direct sampling** from scratch. Then, we use it for three exampples.\n",
    "- Finally, we give the code for **Importance sampling**, which supports both nromalzied and unnormlaized **p(x)**. After that, we test the code for computing an expectation with a few proposal **q(x)**.\n",
    "\n",
    "<hr>\n",
    "\n",
    "https://github.com/ostad-ai/Machine-Learning\n",
    "<br> Explanation: https://www.pinterest.com/HamedShahHosseini/Machine-Learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb296879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8dc6f",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;background:lightblue\">\n",
    "\n",
    "# Direct Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc83f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_monte_carlo(g, sample_generator, n=10000, return_samples=False):\n",
    "    \"\"\"\n",
    "    Method 1. Direct Monte Carlo: E[g(X)] ≈ (1/n) Σ g(X_i), X_i ~ p(x)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    g : function\n",
    "        Function g(x) whose expectation we want\n",
    "    sample_generator : function\n",
    "        Function that returns random samples from p(x)\n",
    "    n : int\n",
    "        Number of samples\n",
    "    return_samples : bool\n",
    "        Whether to return all samples and evaluations\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    estimate : float\n",
    "        Estimate of E[g(X)]\n",
    "    std_error : float\n",
    "        Standard error of estimate\n",
    "    (optional) samples, evaluations : arrays\n",
    "        If return_samples=True\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    evaluations = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        x = sample_generator()\n",
    "        y = g(x)\n",
    "        samples.append(x)\n",
    "        evaluations.append(y)\n",
    "\n",
    "    samples = np.array(samples)\n",
    "    evaluations = np.array(evaluations)\n",
    "\n",
    "    estimate = np.mean(evaluations)\n",
    "    std_error = np.std(evaluations, ddof=1) / np.sqrt(n)\n",
    "\n",
    "    if return_samples:\n",
    "        return estimate, std_error, samples, evaluations\n",
    "    else:\n",
    "        return estimate, std_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36353572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean: 2.9973 ± 0.0199\n",
      "Estimated variance: 3.9499\n",
      "True mean: 3, True variance: 4\n"
     ]
    }
   ],
   "source": [
    "# Example: Estimate E[X] and Var[X] for X ~ Gaussian\n",
    "\n",
    "# True values of mean and variance\n",
    "true_mean,true_var=3,4\n",
    "\n",
    "# Define the target distribution (normal distribution)\n",
    "def sample_normal():\n",
    "    \"\"\"Sample from N(μ, σ)\"\"\"\n",
    "    return np.random.normal(true_mean, np.sqrt(true_var))\n",
    "\n",
    "# Estimate E[X]\n",
    "def g_mean(x):\n",
    "    return x\n",
    "\n",
    "# Estimate E[X²] (for variance)\n",
    "def g_squared(x):\n",
    "    return x**2\n",
    "\n",
    "# Run Monte Carlo\n",
    "mean_estimate, mean_error = direct_monte_carlo(g_mean, sample_normal, n=10000)\n",
    "squared_estimate, squared_error = direct_monte_carlo(g_squared, sample_normal, n=10000)\n",
    "\n",
    "# Calculate variance estimate\n",
    "variance_estimate = squared_estimate - mean_estimate**2\n",
    "print(f\"Estimated mean: {mean_estimate:.4f} ± {mean_error:.4f}\")\n",
    "print(f\"Estimated variance: {variance_estimate:.4f}\")\n",
    "print(f\"True mean: {true_mean}, True variance: {true_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2b74b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated P(X > 1): 0.1596 ± 0.0016\n",
      "True P(X > 1): 0.1587\n"
     ]
    }
   ],
   "source": [
    "# Estimate P(X > 1) for X ~ N(0,1)\n",
    "def sample_standard_normal():\n",
    "    return np.random.normal(0, 1)\n",
    "\n",
    "def indicator_greater_than_1(x):\n",
    "    \"\"\"Indicator function: 1 if x > 1, 0 otherwise\"\"\"\n",
    "    return 1 if x > 1 else 0\n",
    "\n",
    "# Probability is just an expectation of indicator function\n",
    "prob_estimate, prob_error = direct_monte_carlo(\n",
    "    indicator_greater_than_1, \n",
    "    sample_standard_normal, \n",
    "    n=50000\n",
    ")\n",
    "\n",
    "print(f\"Estimated P(X > 1): {prob_estimate:.4f} ± {prob_error:.4f}\")\n",
    "print(f\"True P(X > 1): {0.1587:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b49ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated E[sin(X)exp(-X²)]: 0.135224 ± 0.000458\n",
      "True value (numerical integration): 0.135103\n"
     ]
    }
   ],
   "source": [
    "# Example: Estimate E[sin(X) * exp(-X²)] for X ~ Uniform(0, π)\n",
    "def sample_uniform():\n",
    "    return np.random.uniform(0, np.pi)\n",
    "\n",
    "def complex_function(x):\n",
    "    return np.sin(x) * np.exp(-x**2)\n",
    "\n",
    "estimate, error = direct_monte_carlo(complex_function, sample_uniform, n=100000)\n",
    "print(f\"Estimated E[sin(X)exp(-X²)]: {estimate:.6f} ± {error:.6f}\")\n",
    "\n",
    "# Compare with numerical integration\n",
    "import scipy.integrate as integrate\n",
    "true_value, _ = integrate.quad(lambda x: complex_function(x) * (1/np.pi), 0, np.pi)\n",
    "print(f\"True value (numerical integration): {true_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f4b8b",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;background:lightblue\">\n",
    "\n",
    "# Importance Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d24b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sampling(g, p, sample_q, q_pdf, n=10000, \n",
    "                      normalized_p=True, return_weights=False):\n",
    "    \"\"\"\n",
    "    Method 2. Importance Sampling for estimating E_p[g(X)]\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    g : function\n",
    "        Function g(x) whose expectation we want\n",
    "    p : function\n",
    "        Target distribution PDF. If normalized_p=True, p must integrate to 1.\n",
    "        If normalized_p=False, p can be unnormalized (proportional to true PDF).\n",
    "    sample_q : function\n",
    "        Function that returns random samples from q(x)\n",
    "    q_pdf : function\n",
    "        PDF of proposal distribution q(x) (normalized)\n",
    "    n : int\n",
    "        Number of samples\n",
    "    normalized_p : bool\n",
    "        - True: p is normalized PDF (∫p(x)dx = 1) → uses standard IS\n",
    "        - False: p is unnormalized (p̃(x) ∝ true PDF) → uses self-normalized IS\n",
    "    return_weights : bool\n",
    "        Whether to return weights\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    estimate : float\n",
    "        Estimate of E[g(X)]\n",
    "    effective_n : float\n",
    "        Effective sample size\n",
    "    (optional) weights : array\n",
    "        If return_weights=True\n",
    "    \"\"\"\n",
    "    # Generate samples\n",
    "    samples = np.array([sample_q() for _ in range(n)])\n",
    "    \n",
    "    # Calculate weights: w(x) = p(x)/q(x)\n",
    "    weights = p(samples) / q_pdf(samples)\n",
    "    g_values = g(samples)\n",
    "    \n",
    "    if normalized_p:\n",
    "        # Standard Importance Sampling\n",
    "        # μ̂ = (1/n) Σ w_i * g(x_i)\n",
    "        estimate = np.mean(weights * g_values)\n",
    "        \n",
    "        # Effective sample size for standard IS\n",
    "        # ESS = n / (1 + CV^2) where CV = coefficient of variation of weights\n",
    "        mean_w = np.mean(weights)\n",
    "        if mean_w > 0:\n",
    "            cv2 = np.var(weights) / (mean_w**2)\n",
    "            eff_sample_size = n / (1 + cv2)\n",
    "        else:\n",
    "            eff_sample_size = 0.0\n",
    "            \n",
    "    else:\n",
    "        # Self-Normalized Importance Sampling\n",
    "        # μ̂ = Σ w_i * g(x_i) / Σ w_i\n",
    "        weighted_sum = np.sum(weights * g_values)\n",
    "        total_weight = np.sum(weights)\n",
    "        \n",
    "        if abs(total_weight) > 1e-12:\n",
    "            estimate = weighted_sum / total_weight\n",
    "            \n",
    "            # Effective sample size for self-normalized IS\n",
    "            # ESS = (Σ w_i)^2 / Σ w_i^2\n",
    "            eff_sample_size = (total_weight**2) / np.sum(weights**2)\n",
    "        else:\n",
    "            estimate = 0.0\n",
    "            eff_sample_size = 0.0\n",
    "    \n",
    "    if return_weights:\n",
    "        return estimate, eff_sample_size, weights\n",
    "    else:\n",
    "        return estimate, eff_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8232d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE 2: Importance Sampling\n",
      "============================================================\n",
      "\n",
      "Estimating E[e^X] where X ~ N(0,1):\n",
      "Theoretical value: 1.648721\n",
      "\n",
      "Using n = 10000 samples:\n",
      "Proposal            Estimate        Error       Eff. n   Rel. Error\n",
      "----------------------------------------------------------------------\n",
      "N(0,1)              1.666733     0.018012      10000.0     0.010925\n",
      "N(1,1)              1.648721     0.000000       4120.6     0.000000\n",
      "N(0.5,1.5)          1.661398     0.012677       7766.2     0.007689\n",
      "Laplace(0,1)        1.650747     0.002025       9054.1     0.001228\n"
     ]
    }
   ],
   "source": [
    "# Example: E[e^X] where X ~ N(0,1) using importance sampling\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE 2: Importance Sampling\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Target: E[e^X] where X ~ N(0,1)\n",
    "# Theoretical: E[e^X] = exp(μ + σ²/2) = exp(0 + 1/2) = exp(0.5) ≈ 1.64872\n",
    "\n",
    "g = lambda x: np.exp(x)\n",
    "\n",
    "# Target distribution: N(0,1)\n",
    "p = lambda x: np.exp(-0.5 * x**2) / np.sqrt(2*np.pi)\n",
    "\n",
    "# Try different proposal distributions\n",
    "proposals = [\n",
    "    (\"N(0,1)\",  # Same as target (bad for demonstration)\n",
    "     lambda: np.random.randn(),\n",
    "     lambda x: np.exp(-0.5 * x**2) / np.sqrt(2*np.pi)),\n",
    "\n",
    "    (\"N(1,1)\",  # Shifted Gaussian\n",
    "     lambda: np.random.randn() + 1,\n",
    "     lambda x: np.exp(-0.5 * (x-1)**2) / np.sqrt(2*np.pi)),\n",
    "\n",
    "    (\"N(0.5,1.5)\",  # Different mean and variance\n",
    "     lambda: np.random.randn() * 1.5 + 0.5,\n",
    "     lambda x: np.exp(-0.5 * ((x-0.5)/1.5)**2) / (1.5 * np.sqrt(2*np.pi))),\n",
    "\n",
    "    (\"Laplace(0,1)\",  # Heavy-tailed\n",
    "     lambda: np.random.laplace(0, 1),\n",
    "     lambda x: 0.5 * np.exp(-np.abs(x))),\n",
    "]\n",
    "\n",
    "true_value = np.exp(0.5)\n",
    "n = 10000\n",
    "\n",
    "print(f\"\\nEstimating E[e^X] where X ~ N(0,1):\")\n",
    "print(f\"Theoretical value: {true_value:.6f}\")\n",
    "print(f\"\\nUsing n = {n} samples:\")\n",
    "print(f\"{'Proposal':<15} {'Estimate':>12} {'Error':>12} {'Eff. n':>12} {'Rel. Error':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, sample_q, q_pdf in proposals:\n",
    "    estimate, eff_n = importance_sampling(\n",
    "        g, p, sample_q, q_pdf, n=n\n",
    "    )\n",
    "\n",
    "    error = abs(estimate - true_value)\n",
    "    rel_error = error / true_value\n",
    "\n",
    "    print(f\"{name:<15} {estimate:12.6f} {error:12.6f} \"\n",
    "          f\"{eff_n:12.1f} {rel_error:12.6f}\")\n",
    "\n",
    "# Visualize importance sampling\n",
    "n_samples = 1000\n",
    "\n",
    "# Use N(0.5, 1.5) as proposal\n",
    "proposal_name, sample_q, q_pdf = proposals[2]\n",
    "\n",
    "estimate, eff_n, weights = importance_sampling(\n",
    "    g, p, sample_q, q_pdf, n=n_samples, return_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ace4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
