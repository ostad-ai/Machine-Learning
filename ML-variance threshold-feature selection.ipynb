{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fce00f",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "### Variance threshold for feature selection\n",
    "**Variance threshold** method is one of the simplest **filter**-based **feature selection** techniques. \n",
    "- It removes features whose variance across samples is below a specified threshold\n",
    "    - Under the assumption that features with very low variance contain little useful information for prediction.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Reminder:** **Feature selection** is the process of identifying and retaining the most *relevant* input *variables* (*features*) from a dataset to improve model performance, reduce overfitting, speed up training, and enhance interpretability. \n",
    "- It helps eliminate irrelevant, redundant, or noisy features. \n",
    "\n",
    "<hr> \n",
    "\n",
    "For a feature vector $\\boldsymbol{x}=[x_1,x_2,...,x_n]$ with $n$ samples (we use **sample variance**):\n",
    "- $Variance_{sample}(x)=\\sigma^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(x_iâˆ’\\mu)^2$\n",
    "\n",
    "Where \n",
    "- $\\mu=\\frac{1}{n}\\sum_{i=1}^n x_i$ (**sample mean** of the feature)\n",
    "- $x_i$: is the i-th sample value.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Then, **threshold decision rule** is:\n",
    "- Keep feature $j$ if $\\sigma_j^2 \\ge threshold$\n",
    "- Discard feature $j$ if $\\sigma_j^2\\lt threshold$\n",
    "\n",
    "<hr>\n",
    "\n",
    "In the following, we implement **variance threshold** from scratch and use it with a simple dataset. Each row of the datset is a data point. And each column of the dataset is the samples of a feature.\n",
    "- As a bonus, we also give the code to use `VarianceThreshold` of **Scikit-learn**.\n",
    "\n",
    "<hr>\n",
    "\n",
    "https://github.com/ostad-ai/Machine-Learning\n",
    "<br> Explanation: https://www.pinterest.com/HamedShahHosseini/Machine-Learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d017dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required module\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a867b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold_selection(X, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Select features with variance > threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: 2D NumPy array (n_samples, n_features)\n",
    "    - threshold: minimum variance to keep a feature (default = 0.0)\n",
    "    \n",
    "    Returns:\n",
    "    - X_selected: array with selected features\n",
    "    - selected_indices: indices of kept features\n",
    "    \"\"\"\n",
    "    # Compute variance for each feature (column)\n",
    "    variances = np.var(X, axis=0, ddof=1)  # ddof=1 for sample variance\n",
    "    \n",
    "    # Find features with variance > threshold\n",
    "    selected_indices = np.where(variances > threshold)[0]\n",
    "    \n",
    "    # Select those columns\n",
    "    X_selected = X[:, selected_indices]\n",
    "    \n",
    "    return X_selected, selected_indices, variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e7c394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original variances:\n",
      "[2.91666667e-04 1.66666667e+00 9.50000000e-01]\n",
      "Kept feature indices: [1 2]\n",
      "Selected features:\n",
      " [[ 1.   0.9]\n",
      " [ 2.   1.2]\n",
      " [ 3.   1. ]\n",
      " [ 4.  -0.9]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Feature 0 of X is obviously\n",
    "# the one with least variance\n",
    "X = np.array([\n",
    "    [0.12, 1, 0.9],\n",
    "    [0.14, 2, 1.2],\n",
    "    [0.13, 3, 1.],\n",
    "    [0.1, 4, -0.9]\n",
    "\n",
    "])\n",
    "\n",
    "# Now apply Variance Threshold\n",
    "X_new, kept_idx, vars_ = variance_threshold_selection(X, threshold=0.1)\n",
    "\n",
    "print(f\"Original variances:\\n{vars_}\")\n",
    "print(\"Kept feature indices:\", kept_idx)\n",
    "print(\"Selected features:\\n\", X[:,kept_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4eb13",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;background-color:lightblue\">\n",
    "\n",
    "# Bonus\n",
    "### Feature selection by Variance Threshold using scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b14ad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   0.9]\n",
      " [ 2.   1.2]\n",
      " [ 3.   1. ]\n",
      " [ 4.  -0.9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "X_selected = selector.fit_transform(X)\n",
    "print(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93f698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
